#notes #books #understandingDS #coordination


# System Models
Before we coordinate between the participants in a distributed system, there is some system models along which the system behaves.

1. Communication Link
	1. Fair Loss Link -> messages may be lost and duplicated
	2. Reliable Link -> message are delivered exactly once without loss/duplication
	3. Authenticated Reliable Link -> authenticate the sender + reliable link
2. Types of Failures
	1. Arbitrary Fault -> arbitrary deviation, [Byzantine Model](https://lamport.azurewebsites.net/pubs/byz.pdf)
	2. Crash Recovery -> crash and recover any time
	3. Crash Stop -> crash and doesn't recover
3. Timing Assumptions
	1. Synchronous -> defined amount of time for a given operation
	2. Asynchronous -> unbounded amount of time for a given operation
	3. Partially Synchronous -> real world systems

The major assumptions about the real world models are that they are `fair-loss links`, `crash recovery` processes which are `partially synchronous`

Further Readings
[Unreliable Failure Detectors](https://www.cs.utexas.edu/~lorenzo/corsi/cs380d/papers/p225-chandra.pdf)-> Paper
[Reliable and Secure Distributed Programming](https://www.distributedprogramming.net/) -> Book
[All models are wrong](https://en.wikipedia.org/wiki/All_models_are_wrong) -> Article

# Failure Detection

through pings and heartbeats at its core

# Time

1. Physical Clocks -> need to be synchronized through the NTP
2. Logical Clocks -> Measure the passage of time in terms of the operations (Lamport Clocks)
3. Vector Clocks - > Implemented with an array of counters, for each process in the system. Ensure that the lesser timestamp guarantees one operation happened before another.

Further Reading

[Atomic Clocks](https://en.wikipedia.org/wiki/Atomic_clock) -> Article
[NTP](https://datatracker.ietf.org/doc/html/rfc5905) -> RFC
[Time, Clocks and Ordering](https://lamport.azurewebsites.net/pubs/time-clocks.pdf) -> Paper
[Logical Clocks are Easy](https://queue.acm.org/detail.cfm?id=2917756) -> Article
[Timestamps in Message Passing Systems](https://fileadmin.cs.lth.se/cs/Personal/Amr_Ergawy/dist-algos-papers/4.pdf) -> Paper

# Consensus and Contention

## Leader Election

when the single process needs to access the shared resource, there needs to be a governing authority which guarantees safety and liveness

### Raft Leader Election

![Pasted Image](../Images/Pasted%20image%2020250204004544.png)

Further Reading

[Raft](https://raft.github.io/raft.pdf) -> Paper
[Paxos Made Simple](https://lamport.azurewebsites.net/pubs/paxos-simple.pdf) -> Paper
[Paxos Made Abstract](https://maheshba.bitbucket.io/blog/2021/11/15/Paxos.html) -> Article
[Paxos Made Live](https://static.googleusercontent.com/media/research.google.com/en//archive/paxos_made_live.pdf) -> Paper
# Replication

replication is done to increase the availability of the system, increases the scalability and the performance of the distributed system

## State Machine Replication

the system elects a leader which algos like Raft, leader stores a sequence of the operation in a local log, which it replicated to its followers.

This is coupled with the Append Entries, which ensure that the follower nodes only commit the new operation once a consensus of the followers have received / which ensures a majority of the nodes have the update image

Consensus

ensures that group of nodes decide on a value
• every non-faulty process eventually agrees on a value; 
• the final decision of every non-faulty process is the same everywhere;
• and the value that has been agreed on has been proposed by a process.

Further Readings
[Finite State Machine](https://en.wikipedia.org/wiki/Finite-state_machine) -> Article
[Consensus](<https://en.wikipedia.org/wiki/Consensus_(computer_science)>) -> Article
[ETCD](https://etcd.io/) / [Zookeeper](https://zookeeper.apache.org/)

## Consistency Models

now that we have learnt the basic process to replicate the data across the nodes, there are some consistency levels associated to it, basically whats the deviation between the nodes and how long they take to come in order

1. Strong Consistency -> client exclusively queries the leader, slow but sure process
2. [Sequential Consistency](https://jepsen.io/consistency/models/sequential) -> allows followers to handle the request, guarantees that the all the operations occur in the same order, but not the time it takes to occur on each
3. Eventual Consistency -> The known scenario where the system will eventually converge but there will be some time it can server different results for the same query because the follower nodes are deviated.

Further Reading
[Linearizibility](https://jepsen.io/consistency/models/linearizable) -> Article
[Cap Theorem](https://www.youtube.com/watch?v=hUd_9FENShA) -> YT
[CAP Theorem perspective](https://groups.csail.mit.edu/tds/papers/Gilbert/Brewer2.pdf) -> Paper
[Critique of the CAP Theorem](https://www.cl.cam.ac.uk/research/dtg/archived/files/publications/public/mk428/cap-critique.pdf) -> Paper

[PACELC Theorem](https://en.wikipedia.org/wiki/PACELC_theorem) -> Article

[Consistency Levels in Azure](https://learn.microsoft.com/en-us/azure/cosmos-db/consistency-levels) -> Articles
[Consistency Levels in Cassandra](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html) -> Articles


## Chain Replication

this is a replication protocol , this is more performant than the raft algo, because we are ensuring consistency / replication as well as not dependent on the leader node to conduct the process / or the election process

![Pasted Image](../Images/Pasted%20image%2020250204010652.png)
[Chain Replication](https://www.cs.cornell.edu/home/rvr/papers/OSDI04.pdf) -> Paper
[Object Storage on CRAQ](https://www.usenix.org/legacy/event/usenix09/tech/full_papers/terrace/terrace.pdf) -> Paper


## Coordination Avoidance

total order broadcast and the function that applies the updates at each replica are the two basic parts of a replication

out of which the broadcast is a difficult problem to solve, we have different guarantees when it comes to broadcast.

1. Best Effort -> message is delivered if sender doesn't crash
2. Reliable Broadcast -> message is delivered even if the sender crashes
3. Eager Reliable -> Also a way to implement above, where every node forwards to other nodes
4. [Gossip Protocol](https://en.wikipedia.org/wiki/Gossip_protocol) -> Random forward to other nodes, rather to every node
5. Total Order -> Reliable Broadcast plus ensures that the messages are delivered in order.

[Eventually Consistent Database Types](https://www.microsoft.com/en-us/research/video/strong-eventual-consistency-and-conflict-free-replicated-data-types/) to Read about

1. CRDTs -> [Conflict free replicated data types.](https://inria.hal.science/inria-00609399v1/document)
          [Mutual Inconsistency in Distributed Systems](https://pages.cs.wisc.edu/~remzi/Classes/739/Fall2017/Papers/parker83detection.pdf) -> Paper
2.  [Dynamo Style Databases](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)
3. [Cassandra](https://cassandra.apache.org/_/index.html)
4.  [RIAK Kv](https://riak.com/products/riak-kv/)
5. [Azure Cosmos](https://apps.cs.utexas.edu/tech_reports/reports/tr/TR-2036.pdf)
6. [Google Spanner](https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf)
7. [Cockroach DB](https://www.cockroachlabs.com/)


Further Readings

[CALM Theorem](https://arxiv.org/pdf/1901.01930) -> Paper
[Causal Consistency](https://jepsen.io/consistency/models/causal) -> Article
[Scalable Causal Consistency](https://www.cs.princeton.edu/~mfreed/docs/cops-sosp11.pdf) -> Paper
[Consistency Availability Convergence](https://apps.cs.utexas.edu/tech_reports/reports/tr/TR-2036.pdf) -> Paper
[Guarantees for the Weakly Consistent Replicated data](https://www.cs.utexas.edu/~dahlin/Classes/GradOS/papers/SessionGuaranteesPDIS.pdf) -> Paper

# Transactions

Distributed transaction are difficult to handle when there are so many replicated nodes present in the system with the consistency guarantees provided by the system

Readings
[Transaction Processing](https://en.wikipedia.org/wiki/Transaction_processing) -> Article
[What is ACID](http://www.bailis.org/blog/when-is-acid-acid-rarely/) -> Article
[Postgres Transaction Isolation](https://www.postgresql.org/docs/12/transaction-iso.html)
[Jepsen Database analysis](https://jepsen.io/analyses)

[Two phase locking](https://en.wikipedia.org/wiki/Two-phase_locking) -> Article
[Two Phase commit](https://en.wikipedia.org/wiki/Two-phase_commit_protocol) -> Article
[Time to move on from two phase](https://dbmsmusings.blogspot.com/2019/01/its-time-to-move-on-from-two-phase.html) -> Article

[Concurrency Control](https://www.eecs.harvard.edu/~htk/publication/1981-tods-kung-robinson.pdf) -> Paper
[Multiversion Concurrency Control](https://en.wikipedia.org/wiki/Multiversion_concurrency_control)-> Article

[Uniform Consensus is harder than consensus](https://infoscience.epfl.ch/server/api/core/bitstreams/98490b54-d941-4096-b9d0-d86a4add985d/content) -> Paper
[Logical Physical Clocks and Consistent Snapshots](https://cse.buffalo.edu/tech-reports/2014-04.pdf) -> Paper

## Async Transaction

the two  phase txns are sync blocking txns, which dont really work in the real world scenarios if applied to a whole system. That means the participants are holding locks while waiting for the coordinator, blocking other transactions accessing the same objects from making progress.

[Online Event Processing](https://queue.acm.org/detail.cfm?id=3321612)
[Outbox Pattern](https://microservices.io/patterns/data/transactional-outbox.html)
[Sagas Pattern](https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf)-> Paper
